{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6V5kj2uSzO-"
      },
      "source": [
        "# Fine-tuning distilbert/distilbert-base-multilingual-cased for Greek-Latin Author Labeling\n",
        "\n",
        "The titles of critical editions of Greek texts are often published with Latinized forms of the authors' names and titles. That presents a problem for a project that seeks to catalog only editions of Latin texts. In this context, Greek texts with Latinized author names and titles are false positives, so it is best to winnow them out of the data before seeking to reconcile authors to authority records.\n",
        "\n",
        "I pulled lists of Greek author names from the Thesaurus Linguae Graecae and the Perseus Project (see `python/cleaning_exploration/greek-data-prep.ipynb` for more on the process). \n",
        "\n",
        "I will use those records to train a model to identify Greek and Latin authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import the Required Packages\n",
        "\n",
        "This notebook uses:\n",
        "\n",
        "- `codecarbon` to track energy usage\n",
        "- `datasets` from the HuggingFace API to manage the data\n",
        "- `numpy` for formatting and managing data\n",
        "- `os` to interact with the operating system\n",
        "- `pandas` to manage data\n",
        "- `random` to set a random seed for reproducibility\n",
        "- `scikit-learn` for evaluation metrics\n",
        "- `transformers` from the HuggingFace API to manage the model\n",
        "- `torch` for general machine learning functionality\n",
        "\n",
        "Note that a HuggingFace access token is required. For information, see <https://huggingface.co/docs/hub/security-tokens>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the necessary modules\n",
        "from codecarbon import EmissionsTracker\n",
        "from datasets import Dataset, ClassLabel, Features, Value\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from transformers.data.data_collator import DataCollatorWithPadding\n",
        "from transformers.models.distilbert import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
        "from transformers.trainer_callback import EarlyStoppingCallback\n",
        "from transformers.trainer import Trainer\n",
        "from transformers.training_args import TrainingArguments\n",
        "from transformers.trainer_utils import EvalPrediction, set_seed\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACEad2xiSzPA"
      },
      "source": [
        "## Make Sure the Directory Structure is in Place\n",
        "\n",
        "To keep the information organized, I will make a directory for the model (`greek`) and training logs (`logs`). I will also designate the path for the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMfOBom2SzPB",
        "outputId": "4c504fda-e911-4039-b433-23cdfe9fd86f"
      },
      "outputs": [],
      "source": [
        "# Create paths if they do not exist\n",
        "if not os.path.exists(\"../greek\"):\n",
        "    os.makedirs(\"../greek\")\n",
        "\n",
        "# Establish file directories\n",
        "output_dir = '../greek'  # Directory for saving the model\n",
        "\n",
        "if not os.path.exists(\"../logs\"):\n",
        "    os.makedirs(\"../logs\") # Directory for logs\n",
        "\n",
        "log_dir = '../logs'\n",
        "\n",
        "local_file_path = '../data/deduped_greek_and_latin.csv' # Path to the dataset file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set a Random Seed for Reproducibility\n",
        "\n",
        "Since so much of machine learning depends upon randomness, setting a \"random seed\" makes the randomness consistent across runs, so that the results should be reproducible by anyone running the code in this notebook. The `seed` variable will be called in creating the dataset splits and in setting the parameters for the `Trainer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the random seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Data and Prepare it for Use with the Model\n",
        "\n",
        "The data I gathered from the TLG and Perseus needs to be turned into tensors, the format expected by the model. The following operations load the original data, tokenize the data, convert it into the HuggingFace dataset format, and split the dataset into training, validation, and testing sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y8JXYhVTTC4i"
      },
      "outputs": [],
      "source": [
        "# Load the original CSV file into a pandas DataFrame\n",
        "data = pd.read_csv(local_file_path, encoding='utf-8', quotechar='\"')\n",
        "# Convert 'Name' column to string type to avoid issues with NaN values\n",
        "data['Name'] = data['Name'].astype(str)\n",
        "# Replace NaN values with an empty string\n",
        "data['Name'] = data['Name'].fillna('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Determine the Correct max_length Value\n",
        "\n",
        "Setting a `max_length` ensures that inputs to the model will be consistent in size. It will also make the training faster and more efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVLM0y8bSzPC",
        "outputId": "1733a10f-e45c-4c3e-a36c-aad209b28ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determined max_length for padding/truncation: 20\n"
          ]
        }
      ],
      "source": [
        "# Set TOKENIZERS_PARALLELISM to false to avoid warnings\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-multilingual-cased')\n",
        "\n",
        "# Tokenize the data to find the max length\n",
        "tokens = data['Name'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
        "# Determine the maximum length for padding/truncation. It will be called later in the Trainer.\n",
        "max_length = int(pd.Series(tokens).map(len).quantile(0.95))\n",
        "print(\"Determined max_length for padding/truncation:\", max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert the data into the Dataset format\n",
        "\n",
        "The class `Dataset` in the HuggingFace API has a method for converting pandas dataframes into the expected format. The following block makes use of that. It also updates the dataset to use "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637,
          "referenced_widgets": [
            "e793e0494bb745628e725ca8b60c0746",
            "a7a3843856e94c82b2e1d837121eb4b6",
            "d4920bf989f64156b52b8321ee8abfb2",
            "a891bfbd2d0e462395b6313c1eeb9c1b",
            "8703fbd3817e4cb090ddc50ddfaaf0c5",
            "5699b4aaf1bf4a2b935a54dbc21764a7",
            "f9a7515af59142b28f0cdb948196f7d3",
            "9f55c874bc134df5b28ceb8e25171c23",
            "6b0b8a8067bc4569a3c3e531edcfafd4",
            "3f53482d619941948699e8c973eb72ee",
            "f7816455311442dc8ddbde6585edd9fc"
          ]
        },
        "id": "FSdtxri3SzPC",
        "outputId": "8b49e92f-9da1-4bf5-dfaa-da4f19bfba00"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd0f8ea0d7a14046aa52611344f5d359",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/40458 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create the dataset from pandas\n",
        "hf_dataset = Dataset.from_pandas(data)\n",
        "\n",
        "# Get unique label names\n",
        "label_names = sorted(data['Label'].unique())\n",
        "num_labels = len(label_names)\n",
        "\n",
        "# Define features with ClassLabel\n",
        "features = Features({\n",
        "    'Name': Value('string'),\n",
        "    'Label': ClassLabel(names=label_names)\n",
        "})\n",
        "\n",
        "# Cast the dataset to use these features\n",
        "hf_dataset = hf_dataset.cast(features)\n",
        "\n",
        "# Rename 'Labels' to 'labels' for transformers compatibility\n",
        "hf_dataset = hf_dataset.rename_column('Label', 'labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split the Dataset into Training, Validation, and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VaOJn9-wXDOR"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54b1811450cf4700a32650607ddcc374",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Casting the dataset:   0%|          | 0/40458 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Creating the Hugging Face dataset\n",
        "hf_dataset = Dataset.from_pandas(data)\n",
        "\n",
        "# Define ClassLabel feature\n",
        "label_names = sorted(data['Label'].unique())\n",
        "num_labels = len(hf_dataset.unique('Label'))\n",
        "\n",
        "# Define features with ClassLabel\n",
        "features = Features({\n",
        "    'Name': Value('string'),\n",
        "    'Label': ClassLabel(names=label_names)\n",
        "})\n",
        "\n",
        "# Cast the dataset to the new features including ClassLabel for 'Label'\n",
        "hf_dataset = hf_dataset.cast(features)\n",
        "\n",
        "# Rename 'Label' to 'labels' for transformers compatibility\n",
        "hf_dataset = hf_dataset.rename_column('Label', 'labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split the Dataset into Training, Validation, and Testing Sets\n",
        "\n",
        "Splitting the dataset into training, validation, and testing sets ensures that the model is trained on a representative sample of the dataset, validated against another (smaller) representative sample, and tested with data that has not been used in the training or validation process. The `stratify_by_column` parameter ensures that the labels are evenly distributed across the datasets, and the `seed` parameter helps with reproducibility by ensuring that the same randomness factor is used each time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the dataset into training, validation, and testing sets\n",
        "train_test_split = hf_dataset.train_test_split(test_size=0.2, stratify_by_column='labels',seed=seed)\n",
        "train_val_split = train_test_split['train'].train_test_split(test_size=0.125, seed=seed)  # 0.125 of 0.8 = 0.1 of original\n",
        "\n",
        "train_dataset = train_val_split['train']\n",
        "val_dataset = train_val_split['test']\n",
        "test_dataset = train_test_split['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenize the Dataset\n",
        "\n",
        "This ensures that the dataset is in the format expected by the `Trainer`, defined below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "dbb7a5dd23be46ab8b9f14bd86b0998f",
            "328ba4a6d8b24be3aab342613c84c9b7",
            "62ec3662d8bc4f3c96566975f4da5cc3",
            "6ec82bd0309741f3a78baf9a82612d84",
            "b7bbb34edc5b467ba97a36d51b3d6fe5",
            "63526b2c2403489cb551c10e16c2311b",
            "aa1c883f60c6466886ef0147bc4ebf76",
            "cf368e7332aa4f5084ed5bde06d6c617",
            "5412dc854eba4dd48933a1095d304cf7",
            "3261dd66bb144094a8f79478119cd081",
            "3086a38201214b0aade85d8ce78afe1c",
            "6d7133d2110247e3bae263f2cefd6d56",
            "ace768c2125042928746e8d947f9513d",
            "611ca4a082b142628266b177f96ca97e",
            "c419502d2c934858b33eb2bcfd846e5d",
            "770a7e41b1a24343836cd3c8a8601204",
            "ff6e341801e646b8826d62056380e923",
            "8d12a4030fb3490bb33873fb1c6dea23",
            "60659789b546413bb45da7c723a86035",
            "4cd99e7bbac0473abd983349d3031573",
            "7c68bd36ad0e428593c99542bb105ce3",
            "64dd871f02c8407d9e4d08d6aa88fdfb",
            "c9f877e3dbdb4ab5af27f245ee18f6ad",
            "cbfce0785e5c40409275ed8a57d46c29",
            "1c07172bcb964207ab47b17d69b1df71",
            "f221e704e0cb494dbd293e5c9efff49e",
            "40643aaa6c424fcd813592297935dab2",
            "fdf33b20468540af815c24d5a698db2d",
            "daae64965b7a4c67b0387c4ef80bd664",
            "52e32a1bdf344f2cbdb5665f892612c0",
            "0553dd58b3b748c7b9854df6e877255f",
            "95763141dfdf46b88ed78242bdc6edb9",
            "e38403afc44e4cc183974b9381877e0f"
          ]
        },
        "id": "yuseN-O7SzPD",
        "outputId": "55b54ff8-6a11-4146-9b02-b1d9b1fa23de"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecf518838f634f26910ec2ec057bd202",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/28320 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "177f9c33530a42f89c8e5f010a04fc45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4046 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee2988ae0c7e49a094216c6039b31fe4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/8092 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['Name'], padding=\"max_length\", truncation=True, max_length=max_length)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set the Format of the Dataset for PyTorch\n",
        "\n",
        "The HuggingFace API is really an abstraction of many PyTorch calls, so the dataset must be in the form expected by PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SupbEPYBSzPD",
        "outputId": "254144f0-65cc-4f74-81c8-fd3a99685460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Dataset: Dataset({\n",
            "    features: ['Name', 'labels', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 28320\n",
            "})\n",
            "Validation Dataset: Dataset({\n",
            "    features: ['Name', 'labels', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 4046\n",
            "})\n",
            "Testing Dataset: Dataset({\n",
            "    features: ['Name', 'labels', 'input_ids', 'attention_mask'],\n",
            "    num_rows: 8092\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Set the format for PyTorch\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "# Print the dataset to ensure correct setup\n",
        "print(\"Training Dataset:\", train_dataset)\n",
        "print(\"Validation Dataset:\", val_dataset)\n",
        "print(\"Testing Dataset:\", test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the Number of Labels\n",
        "\n",
        "This counts the number of labels (two in this case: \"Greek\" and \"Latin\") and initializes the model's classification head with the correct number of output units. This is why I don't have to set anything manually for a binary or multiclass classification problem. That is handled automatically based on the value of `num_labels`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVJHhxUqSzPE",
        "outputId": "c82fe89b-91ad-4e3c-b8bc-619f4e4e539f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "num_labels = data['Label'].nunique()\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-multilingual-cased', num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set the Metrics\n",
        "\n",
        "I will use `f1` and `accuracy` as basic metrics for the model's training. More information at <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html> and <https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vIGzaueVSzPF"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred: EvalPrediction):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'f1': f1,\n",
        "        'accuracy': acc\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the TrainingArguments\n",
        "\n",
        "The HuggingFace [`Trainer` class](https://huggingface.co/docs/transformers/main_classes/trainer) has many parameters. I will set a number of them in this array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g9L7Jb5qSzPG"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,              # Directory for saving model and logs\n",
        "    eval_strategy=\"epoch\",              # Evaluate the model every 'eval_steps'\n",
        "    eval_steps=500,                     # Number of steps to run evaluation\n",
        "    logging_dir=log_dir,                # Directory for storing logs\n",
        "    logging_strategy=\"steps\",           # Log metrics every epoch\n",
        "    logging_steps=100,                  # Log metrics every 100 steps\n",
        "    save_strategy=\"epoch\",              # Save checkpoints every 'save_steps'\n",
        "    save_steps=500,                     # Save the model every 500 steps\n",
        "    save_total_limit=1,                 # Limit the total number of checkpoints to save\n",
        "    seed=seed,                          # Set the random seed for reproducibility\n",
        "    per_device_train_batch_size=16,     # Batch size for training\n",
        "    per_device_eval_batch_size=64,      # Batch size for evaluation\n",
        "    num_train_epochs=20,                # Number of training epochs\n",
        "    load_best_model_at_end=True,        # Load the best model at the end of training\n",
        "    metric_for_best_model='f1',         # Use F1 score to find the best model\n",
        "    greater_is_better=True,             # Higher F1 score is better\n",
        "    report_to=[\"tensorboard\"]           # Report metrics to TensorBoard\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use the DataCollator\n",
        "\n",
        "This next block creates a helper that dynamically pads the batches during training and evaluation, increasing efficiency and speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hmfFhMf5ar-u"
      },
      "outputs": [],
      "source": [
        "# Initialize the data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize the Trainer\n",
        "\n",
        "Assemble all the parameters defined above and bundle them into the Trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    processing_class=tokenizer,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Take Advantage of Available GPU or Fallback to CPU\n",
        "\n",
        "The following code checks whether an NVIDIA GPU is available. If not, it checks for an Apple Silicon GPU (which I have). If neither one is available, it defaults to using the CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nMhgN9RPSzPG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: MPS (Apple Silicon GPU)\n"
          ]
        }
      ],
      "source": [
        "# General device selection for Colab (CUDA), Mac (MPS), or CPU fallback\n",
        "if torch.cuda.is_available():\n",
        "    # Set the device to CUDA (NVIDIA GPU)\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using device: CUDA (GPU)\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    # Set the device to MPS (Metal Performance Shaders)\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using device: MPS (Apple Silicon GPU)\")\n",
        "else:\n",
        "    # Fallback to CPU if no GPU is available\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using device: CPU\")\n",
        "\n",
        "# Move the model to the selected device\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Up the EmissionsTracker from CodeCarbon\n",
        "\n",
        "Initialize a tracker and start tracking emissions. Data is printed to the screen and logged in `logs/greek_latin_log.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDje5wYDfwug",
        "outputId": "ee7e90df-0bd3-4a73-9ff3-e23432c8515c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 16:29:19] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 16:29:19] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 16:29:19] No GPU found.\n",
            "[codecarbon INFO @ 16:29:19] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 16:29:19] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon WARNING @ 16:29:19] We saw that you have a Apple M4 Pro but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 16:29:19] CPU Model on constant consumption mode: Apple M4 Pro\n",
            "[codecarbon INFO @ 16:29:19] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 16:29:19]   Platform system: macOS-15.5-arm64-arm-64bit\n",
            "[codecarbon INFO @ 16:29:19]   Python version: 3.10.9\n",
            "[codecarbon INFO @ 16:29:19]   CodeCarbon version: 2.2.2\n",
            "[codecarbon INFO @ 16:29:19]   Available RAM : 24.000 GB\n",
            "[codecarbon INFO @ 16:29:19]   CPU count: 12\n",
            "[codecarbon INFO @ 16:29:19]   CPU model: Apple M4 Pro\n",
            "[codecarbon INFO @ 16:29:19]   GPU count: None\n",
            "[codecarbon INFO @ 16:29:19]   GPU model: None\n"
          ]
        }
      ],
      "source": [
        "# Setup CodeCarbon's EmissionsTracker\n",
        "tracker = EmissionsTracker(\n",
        "    output_dir=\"../logs\",\n",
        "    output_file=\"greek_latin_emissions_log.csv\"\n",
        ")\n",
        "tracker.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "26OHNBX0V2Vz",
        "outputId": "18f648b4-92f5-4541-818a-79bff22bbb66"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17700' max='35400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17700/35400 24:51 < 24:51, 11.86 it/s, Epoch 10/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.158400</td>\n",
              "      <td>0.127411</td>\n",
              "      <td>0.959524</td>\n",
              "      <td>0.959466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.099100</td>\n",
              "      <td>0.122125</td>\n",
              "      <td>0.965314</td>\n",
              "      <td>0.965151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.038800</td>\n",
              "      <td>0.178067</td>\n",
              "      <td>0.970431</td>\n",
              "      <td>0.970341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.052300</td>\n",
              "      <td>0.146946</td>\n",
              "      <td>0.971049</td>\n",
              "      <td>0.971083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.043700</td>\n",
              "      <td>0.171540</td>\n",
              "      <td>0.971154</td>\n",
              "      <td>0.971330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.032700</td>\n",
              "      <td>0.182042</td>\n",
              "      <td>0.969036</td>\n",
              "      <td>0.968858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.167763</td>\n",
              "      <td>0.972818</td>\n",
              "      <td>0.972813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.018100</td>\n",
              "      <td>0.187714</td>\n",
              "      <td>0.971788</td>\n",
              "      <td>0.971824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.019700</td>\n",
              "      <td>0.231125</td>\n",
              "      <td>0.969016</td>\n",
              "      <td>0.969105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.015400</td>\n",
              "      <td>0.204686</td>\n",
              "      <td>0.970425</td>\n",
              "      <td>0.970588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 16:29:34] Energy consumed for RAM : 0.000038 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:29:34] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:29:34] 0.000215 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:29:49] Energy consumed for RAM : 0.000075 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:29:49] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:29:49] 0.000429 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:30:04] Energy consumed for RAM : 0.000113 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:30:04] Energy consumed for all CPUs : 0.000531 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:30:04] 0.000644 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:30:19] Energy consumed for RAM : 0.000150 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:30:19] Energy consumed for all CPUs : 0.000708 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:30:19] 0.000858 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:30:34] Energy consumed for RAM : 0.000188 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:30:34] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:30:34] 0.001073 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:30:49] Energy consumed for RAM : 0.000225 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:30:49] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:30:49] 0.001288 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:31:04] Energy consumed for RAM : 0.000263 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:31:04] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:31:04] 0.001502 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:31:19] Energy consumed for RAM : 0.000300 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:31:19] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:31:19] 0.001717 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:31:34] Energy consumed for RAM : 0.000338 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:31:34] Energy consumed for all CPUs : 0.001594 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:31:34] 0.001932 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:31:49] Energy consumed for RAM : 0.000375 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:31:49] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:31:49] 0.002146 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:32:04] Energy consumed for RAM : 0.000413 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:32:04] Energy consumed for all CPUs : 0.001948 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:32:04] 0.002361 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:32:19] Energy consumed for RAM : 0.000450 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:32:19] Energy consumed for all CPUs : 0.002125 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:32:19] 0.002575 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:32:34] Energy consumed for RAM : 0.000488 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:32:34] Energy consumed for all CPUs : 0.002302 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:32:34] 0.002790 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:32:49] Energy consumed for RAM : 0.000525 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:32:49] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:32:49] 0.003005 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:33:04] Energy consumed for RAM : 0.000563 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:33:04] Energy consumed for all CPUs : 0.002657 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:33:04] 0.003219 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:33:19] Energy consumed for RAM : 0.000600 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:33:19] Energy consumed for all CPUs : 0.002834 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:33:19] 0.003434 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:33:34] Energy consumed for RAM : 0.000638 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:33:34] Energy consumed for all CPUs : 0.003011 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:33:34] 0.003649 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:33:49] Energy consumed for RAM : 0.000675 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:33:49] Energy consumed for all CPUs : 0.003188 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:33:49] 0.003863 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:34:04] Energy consumed for RAM : 0.000713 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:34:04] Energy consumed for all CPUs : 0.003365 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:34:04] 0.004078 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:34:19] Energy consumed for RAM : 0.000750 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:34:19] Energy consumed for all CPUs : 0.003542 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:34:19] 0.004292 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:34:34] Energy consumed for RAM : 0.000788 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:34:34] Energy consumed for all CPUs : 0.003719 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:34:34] 0.004507 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:34:49] Energy consumed for RAM : 0.000825 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:34:49] Energy consumed for all CPUs : 0.003897 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:34:49] 0.004722 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:35:04] Energy consumed for RAM : 0.000863 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:35:04] Energy consumed for all CPUs : 0.004074 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:35:04] 0.004936 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:35:19] Energy consumed for RAM : 0.000900 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:35:19] Energy consumed for all CPUs : 0.004251 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:35:19] 0.005151 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:35:34] Energy consumed for RAM : 0.000938 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:35:34] Energy consumed for all CPUs : 0.004428 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:35:34] 0.005365 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:35:49] Energy consumed for RAM : 0.000975 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:35:49] Energy consumed for all CPUs : 0.004605 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:35:49] 0.005580 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:36:04] Energy consumed for RAM : 0.001013 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:36:04] Energy consumed for all CPUs : 0.004782 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:36:04] 0.005795 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:36:19] Energy consumed for RAM : 0.001050 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:36:19] Energy consumed for all CPUs : 0.004959 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:36:19] 0.006009 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:36:34] Energy consumed for RAM : 0.001088 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:36:34] Energy consumed for all CPUs : 0.005136 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:36:34] 0.006224 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:36:49] Energy consumed for RAM : 0.001125 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:36:49] Energy consumed for all CPUs : 0.005313 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:36:49] 0.006439 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:37:04] Energy consumed for RAM : 0.001163 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:37:04] Energy consumed for all CPUs : 0.005491 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:37:04] 0.006653 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:37:19] Energy consumed for RAM : 0.001200 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:37:19] Energy consumed for all CPUs : 0.005668 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:37:19] 0.006868 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:37:34] Energy consumed for RAM : 0.001238 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:37:34] Energy consumed for all CPUs : 0.005845 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:37:34] 0.007082 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:37:49] Energy consumed for RAM : 0.001275 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:37:49] Energy consumed for all CPUs : 0.006022 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:37:49] 0.007297 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:38:04] Energy consumed for RAM : 0.001313 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:38:04] Energy consumed for all CPUs : 0.006199 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:38:04] 0.007512 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:38:19] Energy consumed for RAM : 0.001350 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:38:19] Energy consumed for all CPUs : 0.006376 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:38:19] 0.007726 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:38:34] Energy consumed for RAM : 0.001388 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:38:34] Energy consumed for all CPUs : 0.006553 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:38:34] 0.007941 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:38:49] Energy consumed for RAM : 0.001425 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:38:49] Energy consumed for all CPUs : 0.006730 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:38:49] 0.008156 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:39:04] Energy consumed for RAM : 0.001463 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:39:04] Energy consumed for all CPUs : 0.006907 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:39:04] 0.008370 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:39:19] Energy consumed for RAM : 0.001500 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:39:19] Energy consumed for all CPUs : 0.007085 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:39:19] 0.008585 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:39:34] Energy consumed for RAM : 0.001538 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:39:34] Energy consumed for all CPUs : 0.007262 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:39:34] 0.008799 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:39:49] Energy consumed for RAM : 0.001575 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:39:49] Energy consumed for all CPUs : 0.007439 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:39:49] 0.009014 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:40:04] Energy consumed for RAM : 0.001613 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:40:04] Energy consumed for all CPUs : 0.007616 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:40:04] 0.009229 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:40:19] Energy consumed for RAM : 0.001650 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:40:19] Energy consumed for all CPUs : 0.007793 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:40:19] 0.009443 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:40:34] Energy consumed for RAM : 0.001688 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:40:34] Energy consumed for all CPUs : 0.007970 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:40:34] 0.009658 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:40:49] Energy consumed for RAM : 0.001725 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:40:49] Energy consumed for all CPUs : 0.008147 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:40:49] 0.009872 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:41:04] Energy consumed for RAM : 0.001763 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:41:04] Energy consumed for all CPUs : 0.008324 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:41:04] 0.010087 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:41:19] Energy consumed for RAM : 0.001800 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:41:19] Energy consumed for all CPUs : 0.008501 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:41:19] 0.010302 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:41:34] Energy consumed for RAM : 0.001838 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:41:34] Energy consumed for all CPUs : 0.008679 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:41:34] 0.010516 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:41:49] Energy consumed for RAM : 0.001875 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:41:49] Energy consumed for all CPUs : 0.008856 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:41:49] 0.010731 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:42:04] Energy consumed for RAM : 0.001913 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:42:04] Energy consumed for all CPUs : 0.009033 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:42:04] 0.010945 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:42:19] Energy consumed for RAM : 0.001950 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:42:19] Energy consumed for all CPUs : 0.009210 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:42:19] 0.011160 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:42:34] Energy consumed for RAM : 0.001988 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:42:34] Energy consumed for all CPUs : 0.009387 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:42:34] 0.011375 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:42:49] Energy consumed for RAM : 0.002025 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:42:49] Energy consumed for all CPUs : 0.009564 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:42:49] 0.011589 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:43:04] Energy consumed for RAM : 0.002063 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:43:04] Energy consumed for all CPUs : 0.009741 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:43:04] 0.011804 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:43:19] Energy consumed for RAM : 0.002100 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:43:19] Energy consumed for all CPUs : 0.009918 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:43:19] 0.012019 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:43:34] Energy consumed for RAM : 0.002138 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:43:34] Energy consumed for all CPUs : 0.010095 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:43:34] 0.012233 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:43:49] Energy consumed for RAM : 0.002175 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:43:49] Energy consumed for all CPUs : 0.010273 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:43:49] 0.012448 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:44:04] Energy consumed for RAM : 0.002213 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:44:04] Energy consumed for all CPUs : 0.010450 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:44:04] 0.012662 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:44:19] Energy consumed for RAM : 0.002250 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:44:19] Energy consumed for all CPUs : 0.010627 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:44:19] 0.012877 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:44:34] Energy consumed for RAM : 0.002288 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:44:34] Energy consumed for all CPUs : 0.010804 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:44:34] 0.013092 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:44:49] Energy consumed for RAM : 0.002325 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:44:49] Energy consumed for all CPUs : 0.010981 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:44:49] 0.013306 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:45:04] Energy consumed for RAM : 0.002363 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:45:04] Energy consumed for all CPUs : 0.011158 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:45:04] 0.013521 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:45:19] Energy consumed for RAM : 0.002400 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:45:19] Energy consumed for all CPUs : 0.011335 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:45:19] 0.013736 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:45:34] Energy consumed for RAM : 0.002438 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:45:34] Energy consumed for all CPUs : 0.011512 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:45:34] 0.013950 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:45:49] Energy consumed for RAM : 0.002475 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:45:49] Energy consumed for all CPUs : 0.011689 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:45:49] 0.014165 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:46:04] Energy consumed for RAM : 0.002513 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:46:04] Energy consumed for all CPUs : 0.011867 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:46:04] 0.014379 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:46:19] Energy consumed for RAM : 0.002550 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:46:19] Energy consumed for all CPUs : 0.012044 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:46:19] 0.014594 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:46:34] Energy consumed for RAM : 0.002588 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:46:34] Energy consumed for all CPUs : 0.012221 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:46:34] 0.014809 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:46:49] Energy consumed for RAM : 0.002625 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:46:49] Energy consumed for all CPUs : 0.012398 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:46:49] 0.015023 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:47:04] Energy consumed for RAM : 0.002663 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:47:04] Energy consumed for all CPUs : 0.012575 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:47:04] 0.015238 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:47:19] Energy consumed for RAM : 0.002700 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:47:19] Energy consumed for all CPUs : 0.012752 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:47:19] 0.015452 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:47:34] Energy consumed for RAM : 0.002738 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:47:34] Energy consumed for all CPUs : 0.012929 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:47:34] 0.015667 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:47:49] Energy consumed for RAM : 0.002775 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:47:49] Energy consumed for all CPUs : 0.013106 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:47:49] 0.015882 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:48:04] Energy consumed for RAM : 0.002813 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:48:04] Energy consumed for all CPUs : 0.013284 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:48:04] 0.016096 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:48:19] Energy consumed for RAM : 0.002850 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:48:19] Energy consumed for all CPUs : 0.013461 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:48:19] 0.016311 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:48:34] Energy consumed for RAM : 0.002888 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:48:34] Energy consumed for all CPUs : 0.013638 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:48:34] 0.016526 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:48:49] Energy consumed for RAM : 0.002925 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:48:49] Energy consumed for all CPUs : 0.013815 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:48:49] 0.016740 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:49:04] Energy consumed for RAM : 0.002963 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:49:04] Energy consumed for all CPUs : 0.013992 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:49:04] 0.016955 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:49:19] Energy consumed for RAM : 0.003000 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:49:19] Energy consumed for all CPUs : 0.014169 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:49:19] 0.017169 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:49:34] Energy consumed for RAM : 0.003038 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:49:34] Energy consumed for all CPUs : 0.014346 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:49:34] 0.017384 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:49:49] Energy consumed for RAM : 0.003075 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:49:49] Energy consumed for all CPUs : 0.014523 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:49:49] 0.017599 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:50:04] Energy consumed for RAM : 0.003113 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:50:04] Energy consumed for all CPUs : 0.014701 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:50:04] 0.017813 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:50:19] Energy consumed for RAM : 0.003150 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:50:19] Energy consumed for all CPUs : 0.014878 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:50:19] 0.018028 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:50:34] Energy consumed for RAM : 0.003188 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:50:34] Energy consumed for all CPUs : 0.015055 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:50:34] 0.018243 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:50:49] Energy consumed for RAM : 0.003225 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:50:49] Energy consumed for all CPUs : 0.015232 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:50:49] 0.018457 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:51:04] Energy consumed for RAM : 0.003263 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:51:04] Energy consumed for all CPUs : 0.015409 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:51:04] 0.018672 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:51:19] Energy consumed for RAM : 0.003300 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:51:19] Energy consumed for all CPUs : 0.015586 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:51:19] 0.018887 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:51:34] Energy consumed for RAM : 0.003338 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:51:34] Energy consumed for all CPUs : 0.015763 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:51:34] 0.019101 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:51:49] Energy consumed for RAM : 0.003375 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:51:49] Energy consumed for all CPUs : 0.015940 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:51:49] 0.019316 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:52:04] Energy consumed for RAM : 0.003413 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:52:04] Energy consumed for all CPUs : 0.016118 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:52:04] 0.019531 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:52:19] Energy consumed for RAM : 0.003450 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:52:19] Energy consumed for all CPUs : 0.016295 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:52:19] 0.019745 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:52:34] Energy consumed for RAM : 0.003488 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:52:34] Energy consumed for all CPUs : 0.016472 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:52:34] 0.019960 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:52:49] Energy consumed for RAM : 0.003525 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:52:49] Energy consumed for all CPUs : 0.016649 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:52:49] 0.020174 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:53:04] Energy consumed for RAM : 0.003563 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:53:04] Energy consumed for all CPUs : 0.016826 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:53:04] 0.020389 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:53:19] Energy consumed for RAM : 0.003600 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:53:19] Energy consumed for all CPUs : 0.017003 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:53:19] 0.020603 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:53:34] Energy consumed for RAM : 0.003638 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:53:34] Energy consumed for all CPUs : 0.017180 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:53:34] 0.020818 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:53:49] Energy consumed for RAM : 0.003675 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:53:49] Energy consumed for all CPUs : 0.017357 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:53:49] 0.021032 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 16:54:04] Energy consumed for RAM : 0.003713 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:54:04] Energy consumed for all CPUs : 0.017534 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:54:04] 0.021247 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=17700, training_loss=0.05660804303878613, metrics={'train_runtime': 1492.4425, 'train_samples_per_second': 379.512, 'train_steps_per_second': 23.72, 'total_flos': 1465420597632000.0, 'train_loss': 0.05660804303878613, 'epoch': 10.0})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCGHrHAxhBJU",
        "outputId": "28c88508-f4b3-4c10-f295-c4c6dc06a6d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[codecarbon INFO @ 16:54:12] Energy consumed for RAM : 0.003731 kWh. RAM Power : 9.000000000000002 W\n",
            "[codecarbon INFO @ 16:54:12] Energy consumed for all CPUs : 0.017620 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:54:12] 0.021351 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estimated CO2 emissions for training: 0.010107928455444129 kg\n"
          ]
        }
      ],
      "source": [
        "# Stop the emissions tracker after training is complete\n",
        "emissions = tracker.stop()\n",
        "\n",
        "print(f\"Estimated CO2 emissions for training: {emissions} kg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the Labels in the Model's Configuration\n",
        "\n",
        "This is important for reproducibility because it ensures the mappings are always explicit and correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "vr1wslSxSzPG",
        "outputId": "43db153c-3067-4092-f727-9dbdc4301c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Greek': 0, 'Latin': 1}\n",
            "{0: 'Greek', 1: 'Latin'}\n"
          ]
        }
      ],
      "source": [
        "label_feature = train_dataset.features['labels']\n",
        "model.config.label2id = {name: i for i, name in enumerate(label_feature.names)}\n",
        "model.config.id2label = {i: name for i, name in enumerate(label_feature.names)}\n",
        "# Check the mappings\n",
        "print(model.config.label2id)\n",
        "print(model.config.id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save the Model with its Tokenizer\n",
        "\n",
        "Saving the model with its tokenizer is an important step for reproducibility, since it makes it easy to reload both the model and tokenizer later for use in inferencing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('../greek/tokenizer_config.json',\n",
              " '../greek/special_tokens_map.json',\n",
              " '../greek/vocab.txt',\n",
              " '../greek/added_tokens.json',\n",
              " '../greek/tokenizer.json')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model and tokenizer\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate the Model on the Test Data\n",
        "\n",
        "When I split the dataset above, I held out 20% of it for testing the model on data it had not yet \"seen\". I'll load the model and evaluate it on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "utk1w4BIbOR4",
        "outputId": "9000473b-bbfa-4edb-9f54-c700186ed99d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='127' max='127' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [127/127 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Results: {'eval_loss': 0.1830487847328186, 'eval_f1': 0.9693772975507846, 'eval_accuracy': 0.9693524468610973, 'eval_runtime': 4.3447, 'eval_samples_per_second': 1862.482, 'eval_steps_per_second': 29.231, 'epoch': 10.0}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "print(\"Test Results:\", test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoJGYyOhbPsx",
        "outputId": "1e7cd7f1-d1b2-49b0-cc7d-73cb9a6e64b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: Juvenal - Predicted Label: Latin\n",
            "Text: Unknown - Predicted Label: Latin\n",
            "Text: Caesar, Julius - Predicted Label: Latin\n",
            "Text: Cicero, Marcus Tullius - Predicted Label: Latin\n",
            "Text: Homer - Predicted Label: Greek\n",
            "Text: Hesiod - Predicted Label: Greek\n",
            "Text: Aristotle - Predicted Label: Greek\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model and tokenizer\n",
        "model = DistilBertForSequenceClassification.from_pretrained('../greek')\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('../greek')\n",
        "# Example texts for inference\n",
        "texts = [\"Juvenal\",\"Unknown\",\"Caesar, Julius\",\"Cicero, Marcus Tullius\",\"Homer\",\"Hesiod\",\"Aristotle\"]\n",
        "\n",
        "# Tokenize the texts\n",
        "inputs = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "# Convert predictions back to labels\n",
        "predicted_labels = [label_feature.int2str(label_id) for label_id in predictions.tolist()]\n",
        "\n",
        "for text, label in zip(texts, predicted_labels):\n",
        "    print(f\"Text: {text} - Predicted Label: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QTHkTmZnyXM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dllml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0553dd58b3b748c7b9854df6e877255f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c07172bcb964207ab47b17d69b1df71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e32a1bdf344f2cbdb5665f892612c0",
            "max": 8092,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0553dd58b3b748c7b9854df6e877255f",
            "value": 8092
          }
        },
        "3086a38201214b0aade85d8ce78afe1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3261dd66bb144094a8f79478119cd081": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328ba4a6d8b24be3aab342613c84c9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63526b2c2403489cb551c10e16c2311b",
            "placeholder": "​",
            "style": "IPY_MODEL_aa1c883f60c6466886ef0147bc4ebf76",
            "value": "Map: 100%"
          }
        },
        "3f53482d619941948699e8c973eb72ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40643aaa6c424fcd813592297935dab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd99e7bbac0473abd983349d3031573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52e32a1bdf344f2cbdb5665f892612c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5412dc854eba4dd48933a1095d304cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5699b4aaf1bf4a2b935a54dbc21764a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60659789b546413bb45da7c723a86035": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "611ca4a082b142628266b177f96ca97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60659789b546413bb45da7c723a86035",
            "max": 4046,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cd99e7bbac0473abd983349d3031573",
            "value": 4046
          }
        },
        "62ec3662d8bc4f3c96566975f4da5cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf368e7332aa4f5084ed5bde06d6c617",
            "max": 28320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5412dc854eba4dd48933a1095d304cf7",
            "value": 28320
          }
        },
        "63526b2c2403489cb551c10e16c2311b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64dd871f02c8407d9e4d08d6aa88fdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b0b8a8067bc4569a3c3e531edcfafd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d7133d2110247e3bae263f2cefd6d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ace768c2125042928746e8d947f9513d",
              "IPY_MODEL_611ca4a082b142628266b177f96ca97e",
              "IPY_MODEL_c419502d2c934858b33eb2bcfd846e5d"
            ],
            "layout": "IPY_MODEL_770a7e41b1a24343836cd3c8a8601204"
          }
        },
        "6ec82bd0309741f3a78baf9a82612d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3261dd66bb144094a8f79478119cd081",
            "placeholder": "​",
            "style": "IPY_MODEL_3086a38201214b0aade85d8ce78afe1c",
            "value": " 28320/28320 [00:01&lt;00:00, 17150.97 examples/s]"
          }
        },
        "770a7e41b1a24343836cd3c8a8601204": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c68bd36ad0e428593c99542bb105ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8703fbd3817e4cb090ddc50ddfaaf0c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d12a4030fb3490bb33873fb1c6dea23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95763141dfdf46b88ed78242bdc6edb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f55c874bc134df5b28ceb8e25171c23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7a3843856e94c82b2e1d837121eb4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5699b4aaf1bf4a2b935a54dbc21764a7",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a7515af59142b28f0cdb948196f7d3",
            "value": "Map: 100%"
          }
        },
        "a891bfbd2d0e462395b6313c1eeb9c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f53482d619941948699e8c973eb72ee",
            "placeholder": "​",
            "style": "IPY_MODEL_f7816455311442dc8ddbde6585edd9fc",
            "value": " 40458/40458 [00:01&lt;00:00, 21778.92 examples/s]"
          }
        },
        "aa1c883f60c6466886ef0147bc4ebf76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ace768c2125042928746e8d947f9513d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff6e341801e646b8826d62056380e923",
            "placeholder": "​",
            "style": "IPY_MODEL_8d12a4030fb3490bb33873fb1c6dea23",
            "value": "Map: 100%"
          }
        },
        "b7bbb34edc5b467ba97a36d51b3d6fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c419502d2c934858b33eb2bcfd846e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c68bd36ad0e428593c99542bb105ce3",
            "placeholder": "​",
            "style": "IPY_MODEL_64dd871f02c8407d9e4d08d6aa88fdfb",
            "value": " 4046/4046 [00:00&lt;00:00, 19411.59 examples/s]"
          }
        },
        "c9f877e3dbdb4ab5af27f245ee18f6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbfce0785e5c40409275ed8a57d46c29",
              "IPY_MODEL_1c07172bcb964207ab47b17d69b1df71",
              "IPY_MODEL_f221e704e0cb494dbd293e5c9efff49e"
            ],
            "layout": "IPY_MODEL_40643aaa6c424fcd813592297935dab2"
          }
        },
        "cbfce0785e5c40409275ed8a57d46c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf33b20468540af815c24d5a698db2d",
            "placeholder": "​",
            "style": "IPY_MODEL_daae64965b7a4c67b0387c4ef80bd664",
            "value": "Map: 100%"
          }
        },
        "cf368e7332aa4f5084ed5bde06d6c617": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4920bf989f64156b52b8321ee8abfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f55c874bc134df5b28ceb8e25171c23",
            "max": 40458,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b0b8a8067bc4569a3c3e531edcfafd4",
            "value": 40458
          }
        },
        "daae64965b7a4c67b0387c4ef80bd664": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbb7a5dd23be46ab8b9f14bd86b0998f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_328ba4a6d8b24be3aab342613c84c9b7",
              "IPY_MODEL_62ec3662d8bc4f3c96566975f4da5cc3",
              "IPY_MODEL_6ec82bd0309741f3a78baf9a82612d84"
            ],
            "layout": "IPY_MODEL_b7bbb34edc5b467ba97a36d51b3d6fe5"
          }
        },
        "e38403afc44e4cc183974b9381877e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e793e0494bb745628e725ca8b60c0746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7a3843856e94c82b2e1d837121eb4b6",
              "IPY_MODEL_d4920bf989f64156b52b8321ee8abfb2",
              "IPY_MODEL_a891bfbd2d0e462395b6313c1eeb9c1b"
            ],
            "layout": "IPY_MODEL_8703fbd3817e4cb090ddc50ddfaaf0c5"
          }
        },
        "f221e704e0cb494dbd293e5c9efff49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95763141dfdf46b88ed78242bdc6edb9",
            "placeholder": "​",
            "style": "IPY_MODEL_e38403afc44e4cc183974b9381877e0f",
            "value": " 8092/8092 [00:00&lt;00:00, 18941.48 examples/s]"
          }
        },
        "f7816455311442dc8ddbde6585edd9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a7515af59142b28f0cdb948196f7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdf33b20468540af815c24d5a698db2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff6e341801e646b8826d62056380e923": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
